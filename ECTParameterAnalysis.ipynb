{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd7c6de",
   "metadata": {},
   "source": [
    "1) Import neccessary libraries and dependencies and setting a seed for reproducibility of experiments and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a25395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rdkit import RDLogger \n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from utils import *\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.utils import from_smiles\n",
    "from dect.directions import generate_uniform_directions \n",
    "from dect.ect import compute_ect_edges\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from utils import seed_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bab09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f77e273",
   "metadata": {},
   "source": [
    "Differences between: \n",
    "\n",
    "- cross_val_score: calculate score for each CV split (In this notebook we use it)\n",
    "- cross_validate: calculate one or more scores and timings for each CV split\n",
    "\n",
    "[More info.](https://datascience.stackexchange.com/questions/28441/what-is-the-difference-between-cross-validate-and-cross-val-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc9f6db",
   "metadata": {},
   "source": [
    "2) Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e2597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/datasetCSV/ADRA1A.csv')\n",
    "print(f\"Loaded {df.shape[0]} molecules from csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc2b89",
   "metadata": {},
   "source": [
    "3) Create a grid of combinations of directions and resolutions numbers for computing the ECT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thetas_list = [10*(i+1) for i in range(10)]\n",
    "# res_list = [10*(i+1) for i in range(10)]\n",
    "thetas_list = [10,20,40,60,80,100, 140, 180, 200]\n",
    "res_list = [10,20,40,60,80,100, 140, 180, 200]\n",
    "param_grid = [(t, r) for t in thetas_list for r in res_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b693c",
   "metadata": {},
   "source": [
    "4) Compute the ect for each combination and compute cross validation for obtain scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list = []\n",
    "for i, smile in tqdm(enumerate(df['smiles']), total=len(df), leave=True, desc=\"Computing molecules graph from smiles\"):\n",
    "  g = from_smiles(smile)\n",
    "  g.x = g.x.float()\n",
    "  graph_list.append(g) \n",
    "  \n",
    "print(f\"Loaded {len(df['smiles'])} molecules from smiles\")\n",
    "\n",
    "scores = []\n",
    "for iter, (theta, res) in tqdm(enumerate(param_grid), total=len(param_grid), leave=True, desc=f\"Computing ECT for different number of directions and resolutions\"):\n",
    "    inicio = time.time()\n",
    "    graph_list_ect = []\n",
    "    v = generate_uniform_directions(num_thetas=theta,d=9,seed=0,device='cpu') #device cpu or cuda as in torch\n",
    "    for g in graph_list:\n",
    "        ect = compute_ect_edges(g.x, g.edge_index, v=v, radius=1, resolution=res, scale=500)\n",
    "        new_g = g.clone()  # evita modificar el grafo original\n",
    "        new_g.ect = ect\n",
    "        graph_list_ect.append(new_g)\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for i in range(len(graph_list_ect)):\n",
    "        X.append(graph_list_ect[i].ect.detach().squeeze().numpy().T.flatten())\n",
    "        y.append(df['target'][i])\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    Xscaled = scaler.transform(X)\n",
    "    y = np.array(y)\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    scoring = {\n",
    "        'rmse': make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred))),\n",
    "        'r2': 'r2',\n",
    "    }\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    results = cross_validate(xgb_model, Xscaled, y, scoring=scoring, cv=cv, return_train_score=True)\n",
    "    rmse = results[\"test_rmse\"].mean()\n",
    "    rmse_std = results[\"test_rmse\"].std()\n",
    "    r2_score = results[\"test_r2\"].mean()\n",
    "    r2_std = results[\"test_r2\"].std()\n",
    "    fin = time.time()\n",
    "    timeSeconds= fin - inicio\n",
    "    scores.append((theta, res, rmse, rmse_std, r2_score, r2_std, timeSeconds))\n",
    "    print(f\" Done for theta: {theta}, res: {res}; in {timeSeconds:.2f} seconds obtaining an RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef06a19",
   "metadata": {},
   "source": [
    "5) We analyse and visualize how both parameters influence the model performance (error), using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'scores' in locals() or 'scores' in globals():\n",
    "    df_scores = pd.DataFrame(scores, columns=[\"theta\", \"res\", \"rmse\",\"rmse_std\",\"r2\", \"r2_std\", \"timeSeconds\"])\n",
    "else:\n",
    "    print(\"No scores found\")\n",
    "\n",
    "pivotRMSE = df_scores.pivot(index=\"theta\", columns=\"res\", values=\"rmse\")\n",
    "pivotSTD = df_scores.pivot(index=\"theta\", columns=\"res\", values=\"rmse_std\")\n",
    "pivotTime = df_scores.pivot(index=\"theta\", columns=\"res\", values=\"timeSeconds\")\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(20, 5))\n",
    "sns.heatmap(pivotRMSE, annot=True, cmap=\"viridis\", linewidth=.5, fmt=\".2f\",ax=axes[0])\n",
    "axes[0].set_title(\"Error RMSE vs num_thetas and resolutions\")\n",
    "sns.heatmap(pivotSTD, annot=True, cmap=\"viridis\", linewidth=.5, fmt=\".2f\",ax=axes[1])\n",
    "axes[1].set_title(\"Error RMSE STD vs num_thetas and resolutions\")\n",
    "sns.heatmap(pivotTime, annot=True, cmap=\"viridis\", linewidth=.5, fmt=\".0f\",ax=axes[2])\n",
    "axes[2].set_title(\"Time Computations (seconds) vs num_thetas and resolutions\")\n",
    "plt.show()\n",
    "\n",
    "if 'scores' in locals() or 'scores' in globals():\n",
    "    df_scores = pd.DataFrame(scores, columns=[\"theta\", \"res\", \"rmse\",\"rmse_std\",\"r2\", \"r2_std\", \"timeSeconds\"])\n",
    "    df_scores.to_csv(\"results/scoresRelationECTparamwitherror.csv\", index=False)\n",
    "else:\n",
    "    df_scores = pd.read_csv(\"results/scoresRelationECTparamwitherror.csv\")\n",
    "\n",
    "pivotRMSE = df_scores.pivot(index=\"theta\", columns=\"res\", values=\"rmse\")\n",
    "pivotSTD = df_scores.pivot(index=\"theta\", columns=\"res\", values=\"rmse_std\")\n",
    "pivotTime = df_scores.pivot(index=\"theta\", columns=\"res\", values=\"timeSeconds\")\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(20, 5))\n",
    "sns.heatmap(pivotRMSE, annot=True, cmap=\"viridis\", linewidth=.5, fmt=\".2f\",ax=axes[0])\n",
    "axes[0].set_title(\"Error RMSE vs num_thetas and resolutions\")\n",
    "sns.heatmap(pivotSTD, annot=True, cmap=\"viridis\", linewidth=.5, fmt=\".2f\",ax=axes[1])\n",
    "axes[1].set_title(\"Error RMSE STD vs num_thetas and resolutions\")\n",
    "sns.heatmap(pivotTime, annot=True, cmap=\"viridis\", linewidth=.5, fmt=\".0f\",ax=axes[2])\n",
    "axes[2].set_title(\"Time Computations (seconds) vs num_thetas and resolutions\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pivotRMSE = df_scores.pivot(index=\"theta\", columns=\"res\", values=\"r2\")\n",
    "pivotSTD = df_scores.pivot(index=\"theta\", columns=\"res\", values=\"r2_std\")\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(20, 5))\n",
    "sns.heatmap(pivotRMSE, annot=True, cmap=\"viridis\", linewidth=.5, fmt=\".2f\",ax=axes[0])\n",
    "axes[0].set_title(\"Error RMSE vs num_thetas and resolutions\")\n",
    "sns.heatmap(pivotSTD, annot=True, cmap=\"viridis\", linewidth=.5, fmt=\".2f\",ax=axes[1])\n",
    "axes[1].set_title(\"Error RMSE STD vs num_thetas and resolutions\")\n",
    "sns.heatmap(pivotTime, annot=True, cmap=\"viridis\", linewidth=.5, fmt=\".0f\",ax=axes[2])\n",
    "axes[2].set_title(\"Time Computations (seconds) vs num_thetas and resolutions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e96e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df_scores['res'])\n",
    "for i in np.unique(df_scores['res']):\n",
    "    df_scores.loc[df_scores['res'] == i].sort_values(by='rmse', ascending=True).head(5)\n",
    "    plt.plot(df_scores.loc[df_scores['res'] == i]['theta'], df_scores.loc[df_scores['res'] == i]['rmse'], label=f\"res: {i}\")\n",
    "\n",
    "plt.xlabel('Number of directions (theta)', fontsize=12)\n",
    "plt.ylabel('RMSE', fontsize=12)\n",
    "plt.legend(title='Resolution', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "np.unique(df_scores['res'])\n",
    "for i in np.unique(df_scores['res']):\n",
    "    df_scores.loc[df_scores['res'] == i].sort_values(by='r2', ascending=True).head(5)\n",
    "    plt.plot(df_scores.loc[df_scores['res'] == i]['theta'], df_scores.loc[df_scores['res'] == i]['r2'], label=f\"res: {i}\")\n",
    "\n",
    "plt.xlabel('Number of directions (theta)', fontsize=12)\n",
    "plt.ylabel('R2', fontsize=12)\n",
    "plt.legend(title='Resolution', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc9080",
   "metadata": {},
   "source": [
    "Boxplot to show error distribution for each number of direction and resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "sns.boxplot(x=\"theta\", y=\"rmse\", data=df_scores, ax=axes[0])\n",
    "axes[0].set_title(\"RMSE distribution according the number of direction (theta)\")\n",
    "axes[0].set_xlabel(\"Number of directions (theta)\")\n",
    "axes[0].set_ylabel(\"RMSE\")\n",
    "\n",
    "sns.boxplot(x=\"res\", y=\"rmse\", data=df_scores, ax=axes[1])\n",
    "axes[1].set_title(\"RMSE distribution according the number of resolutions (res)\")\n",
    "axes[1].set_xlabel(\"Number of resolutions (res)\")\n",
    "axes[1].set_ylabel(\"RMSE\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f143d9a",
   "metadata": {},
   "source": [
    "Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pearson_theta = df_scores['theta'].corr(df_scores['rmse'], method='pearson')\n",
    "corr_spearman_theta = df_scores['theta'].corr(df_scores['rmse'], method='spearman')\n",
    "corr_pearson_res = df_scores['res'].corr(df_scores['rmse'], method='pearson')\n",
    "corr_spearman_res = df_scores['res'].corr(df_scores['rmse'], method='spearman')\n",
    "\n",
    "print(f\"Correlaci贸n Pearson (theta vs rmse): {corr_pearson_theta:.4f}\")\n",
    "print(f\"Correlaci贸n Spearman (theta vs rmse): {corr_spearman_theta:.4f}\")\n",
    "print(f\"Correlaci贸n Pearson (res vs rmse): {corr_pearson_res:.4f}\")\n",
    "print(f\"Correlaci贸n Spearman (res vs rmse): {corr_spearman_res:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
